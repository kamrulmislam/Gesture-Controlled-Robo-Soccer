{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6FhjCJEjLbm"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usT-i7GLdrBW",
        "outputId": "e9c10998-307e-446a-b1f0-ffe1af9896b1"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "altbVfoYR8jl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drGwK_9fSa6E",
        "outputId": "80bcd9d0-e9f6-4ff8-e0c8-2841ddd86204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5peHEoESfFa",
        "outputId": "2c6f82cc-0e54-43a0-d3cf-e93c34ffe40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "high_res/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/\")\n",
        "os.chdir(\"./spectrogram_data/\")\n",
        "!ls -d */"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnyy6PzZS5Ru",
        "outputId": "ec50d515-5e78-48c0-8417-829de84ef51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'up': 0, 'down': 1, 'right': 2, 'left': 3, 'push': 4}\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = \"./high_res\"  # Replace with your folder path\n",
        "BATCH_SIZE = 16 # Small batch size for small data\n",
        "NUM_CLASSES = 5\n",
        "IMG_SIZE = 224\n",
        "CLASSES = [\"up\", \"down\", \"right\", \"left\", \"push\"]\n",
        "CLASS_TO_IDX = {cls_name: idx for idx, cls_name in enumerate(CLASSES)}\n",
        "print(CLASS_TO_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4sffAsLcyju",
        "outputId": "c49b3ce7-52e9-4bd9-dd48-5280ac0ab305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrGlLkDHcLAI"
      },
      "source": [
        "### Pre-processing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw0RwlbVTGHv"
      },
      "outputs": [],
      "source": [
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load image and convert to RGB (3 channels)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od6gsHHqTUCD"
      },
      "outputs": [],
      "source": [
        "def get_data_loaders(data_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
        "    # Validate ratios\n",
        "    assert train_ratio > 0, \"Train split percentage must be greater than 0.\"\n",
        "    assert val_ratio > 0, \"Validation split percentage must be greater than 0.\"\n",
        "    # Using a small epsilon for float comparison\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Train, validation, and test splits must sum to 1.0.\"\n",
        "\n",
        "    # Get all .png files\n",
        "    all_files = glob.glob(os.path.join(data_dir, \"*.png\"))\n",
        "\n",
        "    # Parse labels from filenames\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    print(f\"Found {len(all_files)} images.\")\n",
        "\n",
        "    for f_path in all_files:\n",
        "        filename = os.path.basename(f_path)\n",
        "        parts = filename.split('_')\n",
        "\n",
        "        found_label = None\n",
        "        for part in parts:\n",
        "            if part in CLASS_TO_IDX:\n",
        "                found_label = CLASS_TO_IDX[part]\n",
        "                break\n",
        "\n",
        "        if found_label is not None:\n",
        "            X.append(f_path)\n",
        "            y.append(found_label)\n",
        "        else:\n",
        "            print(f\"Skipping file (no valid class found): {filename}\")\n",
        "\n",
        "    # Initial split: Train and (Validation + Test)\n",
        "    # If val_ratio + test_ratio is 0, this will effectively make X_rem and y_rem empty.\n",
        "    if val_ratio + test_ratio > 0:\n",
        "        X_train, X_rem, y_train, y_rem = train_test_split(\n",
        "            X, y, test_size=(val_ratio + test_ratio), stratify=y, random_state=42\n",
        "        )\n",
        "    else:\n",
        "        X_train, y_train = X, y\n",
        "        X_rem, y_rem = [], []\n",
        "\n",
        "    X_val, y_val = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    if len(X_rem) > 0:\n",
        "        if test_ratio == 0:\n",
        "            # If no test set is needed, the remaining data goes entirely to validation\n",
        "            X_val, y_val = X_rem, y_rem\n",
        "            print(\"Note: Test split is 0%. No separate test loader will be created.\")\n",
        "        else:\n",
        "            # Split the remaining data into validation and test\n",
        "            # Calculate the test_size relative to the 'rem' dataset\n",
        "            # e.g., if val=0.1, test=0.1, then test_size = 0.1 / (0.1 + 0.1) = 0.5\n",
        "            relative_test_size = test_ratio / (val_ratio + test_ratio)\n",
        "            X_val, X_test, y_val, y_test = train_test_split(\n",
        "                X_rem, y_rem, test_size=relative_test_size, stratify=y_rem, random_state=42\n",
        "            )\n",
        "\n",
        "    print(f\"Split sizes -> Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "    # Define Transforms\n",
        "    # Strong augmentation for training to prevent overfitting\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "        # transforms.RandomHorizontalFlip(), # DISABLED for spectrograms usually\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_test_transforms = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create Datasets\n",
        "    train_ds = SpectrogramDataset(X_train, y_train, transform=train_transforms)\n",
        "    val_ds = SpectrogramDataset(X_val, y_val, transform=val_test_transforms)\n",
        "\n",
        "    test_ds = None\n",
        "    if len(X_test) > 0:\n",
        "        test_ds = SpectrogramDataset(X_test, y_test, transform=val_test_transforms)\n",
        "\n",
        "    # Create Loaders\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    test_loader = None\n",
        "    if test_ds is not None:\n",
        "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O90ZT38rcUaB",
        "outputId": "c3e206a8-2638-4ab9-f6de-ad00ab0be48a"
      },
      "outputs": [],
      "source": [
        "# train_loader, val_loader, test_loader = get_data_loaders(DATA_DIR, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\n",
        "\n",
        "train_loader, val_loader, test_loader = get_data_loaders(DATA_DIR, train_ratio=0.8, val_ratio=0.2, test_ratio=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF_tcJqocC0c"
      },
      "source": [
        "### Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mg93SUOc1aa"
      },
      "source": [
        "#### Different Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJXt-XMb3go"
      },
      "outputs": [],
      "source": [
        "def build_convnext_tiny(num_classes, freeze_layers=True):\n",
        "    # Load Pre-trained ConvNeXt Tiny\n",
        "    # 'DEFAULT' weights are usually ImageNet-1K\n",
        "    model = models.convnext_tiny(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        # Freeze all parameters in the feature extraction layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    last_layer_input = model.classifier[2].in_features\n",
        "    model.classifier[2] = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_resnet18(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds and modifies a pre-trained ResNet18 model for custom classification.\n",
        "    \"\"\"\n",
        "    # Load ResNet18 pre-trained on ImageNet\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    if freeze_layers:\n",
        "        # Freeze all parameters in the feature extraction layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Get the number of input features to the final fully-connected (fc) layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "\n",
        "    # Replace the classification head to match the number of classes\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    print(f\"ResNet18 loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_efficientnet_b0(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds and modifies a pre-trained EfficientNet-B0 model.\n",
        "    \"\"\"\n",
        "    # Load EfficientNet-B0 pre-trained on ImageNet\n",
        "    # 'DEFAULT' uses IMAGENET1K_V1\n",
        "    model = models.efficientnet_b0(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        # Freeze all parameters in the feature extraction layers\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # EfficientNet's classifier is a Sequential layer. We replace the last Linear layer (index [1])\n",
        "    # The input features are taken from the second to last layer\n",
        "    last_layer_input = model.classifier[1].in_features\n",
        "\n",
        "    # Create a new classifier with the correct output size\n",
        "    model.classifier[1] = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    print(f\"EfficientNet-B0 loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_mobilenet_v3_large(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds MobileNetV3 Large.\n",
        "    \"\"\"\n",
        "    model = models.mobilenet_v3_large(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # MobileNetV3 classifier is a Sequential block. The last layer is the Linear one.\n",
        "    # model.classifier[-1] is the final Linear layer\n",
        "    last_layer_input = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    print(f\"MobileNetV3 Large loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_densenet121(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds DenseNet121.\n",
        "    \"\"\"\n",
        "    model = models.densenet121(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # DenseNet classifier is a single Linear layer named 'classifier'\n",
        "    last_layer_input = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    print(f\"DenseNet121 loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_resnet50(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds ResNet50.\n",
        "    \"\"\"\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    print(f\"ResNet50 loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_vgg16(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds VGG16 (with Batch Normalization).\n",
        "    \"\"\"\n",
        "    # Using BN version for better training stability\n",
        "    model = models.vgg16_bn(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # VGG classifier is a Sequential block.\n",
        "    # The last layer is at index 6\n",
        "    last_layer_input = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    print(f\"VGG16 (BN) loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "def build_vgg19(num_classes, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Builds VGG19 (with Batch Normalization).\n",
        "    \"\"\"\n",
        "    model = models.vgg19_bn(weights='DEFAULT')\n",
        "\n",
        "    if freeze_layers:\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    last_layer_input = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(last_layer_input, num_classes)\n",
        "\n",
        "    print(f\"VGG19 (BN) loaded. Final layer output set to {num_classes} classes.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK-aE9Y-hFB3"
      },
      "outputs": [],
      "source": [
        "def get_model(model_name):\n",
        "    if model_name == 'convnext_tiny':\n",
        "        return build_convnext_tiny(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'resnet18':\n",
        "        return build_resnet18(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'efficientnet_b0':\n",
        "        return build_efficientnet_b0(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'mobilenet_v3_large':\n",
        "        return build_mobilenet_v3_large(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'densenet121':\n",
        "        return build_densenet121(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'resnet50':\n",
        "        return build_resnet50(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'vgg16':\n",
        "        return build_vgg16(NUM_CLASSES)\n",
        "\n",
        "    elif model_name == 'vgg19':\n",
        "        return build_vgg19(NUM_CLASSES)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} not implemented.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hspe5-1c63K"
      },
      "source": [
        "#### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj12QbPUclor"
      },
      "outputs": [],
      "source": [
        "# Model names: 'convnext_tiny', 'resnet18', 'efficientnet_b0', 'mobilenet_v3_large', 'densenet121', 'resnet50', 'vgg16', 'vgg19'\n",
        "model_name = 'convnext_tiny'\n",
        "\n",
        "model = get_model(model_name)\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab99555",
        "outputId": "04843dc9-c9fb-47f8-d90f-812b42c55745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "ConvNeXt                                      [1, 5]                    --\n",
              "├─Sequential: 1-1                             [1, 768, 7, 7]            --\n",
              "│    └─Conv2dNormActivation: 2-1              [1, 96, 56, 56]           --\n",
              "│    │    └─Conv2d: 3-1                       [1, 96, 56, 56]           (4,704)\n",
              "│    │    └─LayerNorm2d: 3-2                  [1, 96, 56, 56]           (192)\n",
              "│    └─Sequential: 2-2                        [1, 96, 56, 56]           --\n",
              "│    │    └─CNBlock: 3-3                      [1, 96, 56, 56]           (79,296)\n",
              "│    │    └─CNBlock: 3-4                      [1, 96, 56, 56]           (79,296)\n",
              "│    │    └─CNBlock: 3-5                      [1, 96, 56, 56]           (79,296)\n",
              "│    └─Sequential: 2-3                        [1, 192, 28, 28]          --\n",
              "│    │    └─LayerNorm2d: 3-6                  [1, 96, 56, 56]           (192)\n",
              "│    │    └─Conv2d: 3-7                       [1, 192, 28, 28]          (73,920)\n",
              "│    └─Sequential: 2-4                        [1, 192, 28, 28]          --\n",
              "│    │    └─CNBlock: 3-8                      [1, 192, 28, 28]          (306,048)\n",
              "│    │    └─CNBlock: 3-9                      [1, 192, 28, 28]          (306,048)\n",
              "│    │    └─CNBlock: 3-10                     [1, 192, 28, 28]          (306,048)\n",
              "│    └─Sequential: 2-5                        [1, 384, 14, 14]          --\n",
              "│    │    └─LayerNorm2d: 3-11                 [1, 192, 28, 28]          (384)\n",
              "│    │    └─Conv2d: 3-12                      [1, 384, 14, 14]          (295,296)\n",
              "│    └─Sequential: 2-6                        [1, 384, 14, 14]          --\n",
              "│    │    └─CNBlock: 3-13                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-14                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-15                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-16                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-17                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-18                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-19                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-20                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    │    └─CNBlock: 3-21                     [1, 384, 14, 14]          (1,201,920)\n",
              "│    └─Sequential: 2-7                        [1, 768, 7, 7]            --\n",
              "│    │    └─LayerNorm2d: 3-22                 [1, 384, 14, 14]          (768)\n",
              "│    │    └─Conv2d: 3-23                      [1, 768, 7, 7]            (1,180,416)\n",
              "│    └─Sequential: 2-8                        [1, 768, 7, 7]            --\n",
              "│    │    └─CNBlock: 3-24                     [1, 768, 7, 7]            (4,763,136)\n",
              "│    │    └─CNBlock: 3-25                     [1, 768, 7, 7]            (4,763,136)\n",
              "│    │    └─CNBlock: 3-26                     [1, 768, 7, 7]            (4,763,136)\n",
              "├─AdaptiveAvgPool2d: 1-2                      [1, 768, 1, 1]            --\n",
              "├─Sequential: 1-3                             [1, 5]                    --\n",
              "│    └─LayerNorm2d: 2-9                       [1, 768, 1, 1]            (1,536)\n",
              "│    └─Flatten: 2-10                          [1, 768]                  --\n",
              "│    └─Linear: 2-11                           [1, 5]                    3,845\n",
              "===============================================================================================\n",
              "Total params: 27,823,973\n",
              "Trainable params: 3,845\n",
              "Non-trainable params: 27,820,128\n",
              "Total mult-adds (Units.MEGABYTES): 321.61\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 131.27\n",
              "Params size (MB): 111.27\n",
              "Estimated Total Size (MB): 243.14\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# input size is (Batch_Size, Channels, Height, Width)\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAtZ9eKBbcUA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HqFowCPU83t"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC4SUGpRk6zz"
      },
      "source": [
        "#### Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj6ClGi1U8uc"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=25, patience=5, save_dir='training_results'):\n",
        "\n",
        "    # 1. Setup Directories\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    # Track history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [],\n",
        "        'lr': []\n",
        "    }\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    patience_counter = 0  # To track early stopping\n",
        "\n",
        "    print(f\"Starting training for {num_epochs} epochs...\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            # Store metrics\n",
        "            if phase == 'train':\n",
        "                history['train_loss'].append(epoch_loss)\n",
        "                history['train_acc'].append(epoch_acc.item())\n",
        "\n",
        "                # Track current Learning Rate\n",
        "                current_lr = optimizer.param_groups[0]['lr']\n",
        "                history['lr'].append(current_lr)\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} LR: {current_lr:.6f}')\n",
        "            else:\n",
        "                history['val_loss'].append(epoch_loss)\n",
        "                history['val_acc'].append(epoch_acc.item())\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # Deep Copy the model if it's the best one so far (based on Loss)\n",
        "                if epoch_loss < best_val_loss:\n",
        "                    best_val_loss = epoch_loss\n",
        "                    best_val_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    patience_counter = 0 # Reset counter\n",
        "\n",
        "                    # Save Checkpoint immediately\n",
        "                    torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "        # Step the scheduler at the end of the epoch\n",
        "        if scheduler is not None:\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                # Reduce LR On Plateau requires the validation metric\n",
        "                scheduler.step(history['val_loss'][-1])\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "        print(f\"Time: {time.time() - epoch_start:.2f}s\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Check Early Stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered! No improvement in Val Loss for {patience} epochs.\")\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best Val Loss: {best_val_loss:.4f} | Best Val Acc: {best_val_acc:.4f}')\n",
        "\n",
        "    # Save metrics to JSON for later plotting\n",
        "    history_path = os.path.join(save_dir, 'training_metrics.json')\n",
        "\n",
        "    def default(obj):\n",
        "        if isinstance(obj, (np.float32, torch.Tensor)):\n",
        "            return float(obj)\n",
        "        raise TypeError\n",
        "\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f, default=default)\n",
        "    print(f\"Metrics saved to {history_path}\")\n",
        "\n",
        "    # Load best model weights before returning\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5laSVPAMU8qn"
      },
      "outputs": [],
      "source": [
        "def plot_results(history_path='training_results/training_metrics.json'):\n",
        "    # Load data\n",
        "    if isinstance(history_path, str):\n",
        "        with open(history_path, 'r') as f:\n",
        "            history = json.load(f)\n",
        "    else:\n",
        "        history = history_path\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['train_acc'], 'b-', label='Training Acc')\n",
        "    plt.plot(epochs, history['val_acc'], 'r-', label='Validation Acc')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxEHKCsk-8e"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2vR0hcNlCh6"
      },
      "outputs": [],
      "source": [
        "training_results_path = f'./training_results_{model_name}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w3HsqeDU8gs"
      },
      "outputs": [],
      "source": [
        "# Setup Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "# Add Scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "training_results_path = f'./training_results_{model_name}'\n",
        "\n",
        "# Train\n",
        "model, history = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=30,\n",
        "    patience=6,\n",
        "    save_dir=training_results_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "FnFLoo-MU1Bi",
        "outputId": "5689c7e1-c345-4c1c-a004-ae09e76cc677"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "plot_results(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGk-gwMDDzOk"
      },
      "source": [
        "#### Run all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DJThmyhGD2OC",
        "outputId": "ff68ec2d-74de-40ed-c074-2a1ae8c4a1f1"
      },
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    'convnext_tiny',\n",
        "    'resnet18',\n",
        "    'efficientnet_b0',\n",
        "    'mobilenet_v3_large',\n",
        "    'densenet121',\n",
        "    'resnet50',\n",
        "    'vgg16',\n",
        "    'vgg19'\n",
        "]\n",
        "# model_name = 'convnext_tiny'\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"Training for model: {model_name}\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    model = get_model(model_name)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Setup Loss & Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Only optimize parameters that require gradients (the head)\n",
        "    # Start with a slightly higher LR for the head\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "    # Add Scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    training_results_path = f'./training_results_{model_name}'\n",
        "\n",
        "    # Train\n",
        "    model, history = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        scheduler=scheduler,\n",
        "        num_epochs=30,\n",
        "        patience=6,\n",
        "        save_dir=training_results_path\n",
        "    )\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    # Plot\n",
        "    plot_results(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FxNd7JbTc2"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqFIkqRDYYTw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj5N7hLnhrvb"
      },
      "source": [
        "#### Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix2EislhYfG2"
      },
      "outputs": [],
      "source": [
        "def evaluate_test_set(model, test_loader):\n",
        "    if test_loader is None:\n",
        "        print(\"No test loader provided. Skipping test set evaluation.\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Running evaluation on Test Set...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # --- Metrics ---\n",
        "    # 1. Classification Report (Precision, Recall, F1)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=CLASSES))\n",
        "\n",
        "    # 2. Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrcahU-RYscy"
      },
      "outputs": [],
      "source": [
        "def predict_single_image(model, image_path, transform):\n",
        "    \"\"\"\n",
        "    Reads an image, applies transforms, and predicts the class.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Load Image\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return\n",
        "\n",
        "    # Apply Transform (Must match Validation/Test transforms)\n",
        "    # Add batch dimension (C, H, W) -> (1, C, H, W)\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "\n",
        "        # Get Probabilities using Softmax\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        # Get Top Prediction\n",
        "        max_prob, pred_idx = torch.max(probs, 1)\n",
        "\n",
        "    predicted_class = CLASSES[pred_idx.item()]\n",
        "    confidence = max_prob.item() * 100\n",
        "\n",
        "    return predicted_class, confidence, probs[0].cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y9dLCKShwIO"
      },
      "source": [
        "#### Best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1bXBxQUY4hN",
        "outputId": "22f1e54d-b22b-4591-89b6-4d16a99aeb6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 109M/109M [00:00<00:00, 259MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading model...\")\n",
        "\n",
        "# Model names: 'convnext_tiny', 'resnet18', 'efficientnet_b0'\n",
        "model_name = 'convnext_tiny'\n",
        "\n",
        "model = get_model(model_name)\n",
        "model = model.to(device)\n",
        "\n",
        "# Load weights\n",
        "model_path = f'training_results_{model_name}/best_model.pth'\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(\"Weights loaded successfully.\")\n",
        "else:\n",
        "    print(\"Error: 'best_model.pth' not found. Train the model first.\")\n",
        "    exit()\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLGVENOeh3tW"
      },
      "source": [
        "#### Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "7Xmm7gi5ZZ9C",
        "outputId": "82335283-270e-4a17-ba93-f5ca32f71b62"
      },
      "outputs": [],
      "source": [
        "# Test with Test Loader\n",
        "evaluate_test_set(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ne3gTAQgJxP"
      },
      "source": [
        "#### Single Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "y_pCc3w6ZVAq",
        "outputId": "93bf6ec1-3a79-4646-f204-a95a04b802e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Image: /content/drive/MyDrive/ECE 592 Intro to Radar Project/Gesture_code/test_data/k_left_1.png\n",
            "Prediction: PUSH\n",
            "Confidence: 58.30%\n",
            "------------------------------\n",
            "Class Probabilities:\n",
            "  up: 9.48%\n",
            "  down: 1.36%\n",
            "  right: 3.01%\n",
            "  left: 27.86%\n",
            "  push: 58.30%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test with Single Image\n",
        "TEST_DATA_DIR = \"./test_data\"\n",
        "image_name = \"k_left_1.png\"\n",
        "test_image_path = f\"{TEST_DATA_DIR}/{image_name}\" # Replace with a real path\n",
        "\n",
        "# We need the validation transforms here\n",
        "from torchvision import transforms\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    pred_class, conf, all_probs = predict_single_image(model, test_image_path, val_transforms)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Image: {test_image_path}\")\n",
        "    print(f\"Prediction: {pred_class.upper()}\")\n",
        "    print(f\"Confidence: {conf:.2f}%\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Optional: Print all probabilities\n",
        "    print(\"Class Probabilities:\")\n",
        "    for i, cls in enumerate(CLASSES):\n",
        "        print(f\"  {cls}: {all_probs[i]*100:.2f}%\")\n",
        "\n",
        "    # Optional: Display the image with prediction title\n",
        "    plt.imshow(Image.open(test_image_path))\n",
        "    plt.title(f\"Pred: {pred_class} ({conf:.1f}%)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Test image not found: {test_image_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSCpsNrmDjNS"
      },
      "source": [
        "#### Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bgt8sEqDkiA"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the training set\n",
        "evaluate_test_set(model, train_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
